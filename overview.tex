\section{Overview}

\subsection{B-Link Tree}

B-Link trees are an extension to B+ trees proposed by \citeauthor{b-link} in \citeyear{b-link} to support concurrent access with minimal locking. Like B+ trees, they are self-balancing data structures with an adjustable fan-out factor that store all data at leaf nodes. B-Link trees introduce additional linkages between nodes and ensure that no more than three nodes are locked at a time-per transaction \cite{b-link}.


\subsection{FPGA}

Field-Programmable Gate Arrays (FPGAs) are an alternative processing element to CPUs. Structurally, FPGAs are large arrays of reconfigurable logic gates that can be used to implement complex digital circuits. The ability to design digital circuits directly allows for the kind of parallelism of GPUs traditionally associated with GPUS, and their reconfigurability is analogous to the flexibility of CPUs to perform many different kinds of tasks.

One application that FPGAs are uniquely for is networking, as the dataflow programming model aligns well with the way that streams of data are processed in high-throughput networking scenarios. FPGAs have seen increasing deployment in datacenters as a means to improve the underlying datacenter infrastructure \cite{bobda-trets-2022,fang-vldb-2020}, rather than simply as accelerators as GPUs are.


\subsection{RDMA}

Remote Direct Memory Access (RDMA) is an extension to the concept of direct memory access (DMA), which a system's memory to be accessed without the involvement of its CPU. RDMA is a standard allowing for such transactions to take place over a network rather than a local link like PCIe. Compared to traditional networking protocols, RDMA is significantly faster, moving the bottleneck of distributed systems out of the networking portion and into processing portion \cite{binnig-vldb-2016}.

RDMA has also seen widespread datacenter adoption, though primarily on CPU-based systems that use specialized network interface cards (NICs) to handle RDMA operations. \citet{star} have shown the viability of FPGAs as network accelerators, but \citeauthor{star} use them to implement custom a NIC rather than as part of an application \cite{star}.

RDMA operations, or ``verbs'', can be either one-sided or two-sided. One-sided operations access memory at a specific location on the remote node. These are lightweight and simple to implement, but are more difficult for applications to use. Two-sided operations allows the remote node to chose the specific address in its own memory \cite{base}, which imposes a burden on the remote CPU. The channel-like nature of two-sided verbs can provide stronger guarantees, which can increase efficiency on the networking side.

For CPU-based systems, the tradeoff between CPU usage and network usage is an important consideration for choosing which type of verbs to use. In FPGA-based systems, they function near identically. CPUs must dedicate some cycles away from their other tasks in order to manage two-sided RDMA calls, as computation needs to be multiplexed temporally. FPGAs are multiplexed spatially in terms of available gates, so some of these gates can be dedicated to handling two-sided RDMA without imposing overhead on the rest of the system, so long as there are available gates.
