\sect{Compute Node Architecture}

\subsect{Memory Layout}

Even without the considerations of caching that would arise on CPU-based
systems, memory access patterns can stil have significant performance impacts.

The XCU280 FPGA integrates $\SI{8}{\giga\byte}$ of on-chip High-Bandwidth Memory
(HBM) with a theoretical maximum bandwidth of $\SI{460}{\giga\byte\per\second}$
\autocite{u280}, but this is contingent on spreading out the accesses among all
available channels \autocite{holzinger-ipdpsw-2021}.

Though using HLS prevents some of the lower-level access optimizations proposed
by \citeauthor{holzinger-ipdpsw-2021}, it is still possible to reap some
benefits by controlling memory access patterns. Because the manner that the
abstract tree is accessed is dictated by \citeauthor{b-link}'s original
algorithm, the best way to optimize memory accesses is to consider how best to
lay out the tree in memory.
