\sect{Related Works}

% \subsect{SmartNICs}

Several designs \autocite{honeycomb,strom,star} use the SmartNICs mentioned in
\ref{sec:datacenter-fpga} to implement a small subset of the processing required
for a complete tree. These NICs sit between several nodes of a cluster connected
using RDMA where the majority of the application processing still takes place on
the host CPUs.

In \citetitle{star}, \citeauthor{star} have shown the viability of FPGAs as
network accelerators, but use them to implement a custom NIC protocol rather
than as part of an application \autocite{star}.

% Utilizing more of the U280's memory hierarchy that could be leveraged for some
% of these caching effects. In addition to the $\SI{8}{\giga\byte}$ of HBM used in
% this experiment, it has $\SI{32}{\giga\byte}$ of slower, off-chip DDR and
% $\SI{41}{\kilo\byte}$ of faster, on-chip block RAM (BRAM) and UltraRAM (URAM).

\citetitle{honeycomb} uses a hybrid approach, with the CPU handling modification
operations and an FPGA-based SmartNIC handling lookup operations. The main
reason that \citeauthor{honeycomb} give for this approach is that the cost of
accelerating modification operations was too high due to their complexity to be
beneficial in read-dominated workloads \autocite{honeycomb}. The U280 that we
are using is more capable than Honeycomb's embedded FPGA, so ``program space''
is not as much of a concern. Using Vitis HLS allows for these more complex
procedures to be described in a traditional software context, lowering the
amount of effort required to implement them effectively.

\citetitle{strom} is another design that leverages SmartNIC FPGAs for
processing, but uses them to accelerate tracing pointers between multiple nodes
of a distributed tree \autocite{strom}.

\citeauthor{ren-fpl-2019} propose an FPGA B-Tree that differentiates itself by
support for version snapshots. In this case, all operations except for range
queries are fully handled by the FPGA. They use a Xilinx KCU105 with
$\SI{2}{\giga\byte}$ of DDR4 and a tree of order $m=8$. Despite the lower memory
size and bandwidth, they still observed an order of magnitude in performance with
gains over a purely CPU solution \autocite{ren-fpl-2019}.
