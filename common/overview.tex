\sect{Overview}

\subsect{Database Indexing}
\label{sec:indexing}

It is common for modern databases to use a variant of the B-Tree for indexing
\autocite{ma-tpds-2022}. Shorter trees yield faster lookups, as lookup time is
proportional to the length of the path from the root node where the search
begins to the node holding the desired data. The self-balancing nature of
B-Trees helps to control the height of the tree and thus lookup times. B+ trees
are a variant of B trees the keep all data values at the leaves rather than
storing them at all levels of the tree, which improves the average case time of
tree traversal in terms of number of I/O operations.

B-Link trees are an extension to B+ trees proposed by \citeauthor{b-link} in
\citeyear{b-link} which add fields to provide for thread-safe access. Like B+
trees, they are self-balancing, have an adjustable fan-out factor, and store all
data at leaf nodes. B-Link trees introduce linkages between sibling nodes at all
levels of the tree. Principally, this is to ensure that newly created sibling
nodes are still accessible during split operations, even if they have not yet
been assigned to a parent node. This structure ensures that no more than three
nodes are locked at a time for each modification operation. However, this also
brings the benefit that range-based queries can be executed very easily, as
subsequent leaf nodes form a linked list \autocite{b-link}.


\subsect{FPGAs, HDLs, and HLS}
\label{sec:fpga}

Field-Programmable Gate Arrays (FPGAs) are an alternative processing element to
CPUs. Structurally, FPGAs are large arrays of reconfigurable logic gates that
can be used to implement complex digital circuits. This lower-level approach
allows for designs to exploit more parallelism than CPUs. FPGAs will not perform
as well as application-specific integrated circuits (ASICs) for an identical
design, but on-demand reconfigurability, shorter lead times, and lower upfront
cost offsets these downsides in many applications.

A key difference of FPGAs from CPUs is how computational resources are
multiplexed. On CPU-based systems, computational resources are multiplexed
temporally; there are a limited number of instructions that can be executed each
second. FPGAs are multiplexed spatially; all processes can run simultaneously so
long as there are sufficient gates available to implement them.

Traditionally, FPGA designs are written in hardware description languages
(HDLs), with the two most prominent being Verilog and VHDL. However, in recent
years attempts have been made to change this. High-Level Synthesis (HLS)
frameworks convert programs written in traditional programming languages like C
\& C++ into an HDL that can be synthesized. This allows for easier conversion of
existing algorithms and codebases as well as increasing the pool of potential
developers \autocite{martin-destest-2009}. More recently, projects like Chisel
have sought to blur the line between software and HDL by extending the Scala programming language to support HDL
semantics \autocite{chisel}.


\subsect{FPGAs in the Datacenter}
\label{sec:datacenter-fpga}

Originally, FPGAs were intended for prototyping ASICs, but later found wide
usage in the telecom industry \autocite{bobda-trets-2022,mencer-queue-2020} and
more recently in datacenters \autocite{mencer-queue-2020,hoozemans-cas-2021}.
FPGAs are uniquely suited to networking applications because the dataflow
programming model \autocite{hoozemans-cas-2021} inherent to their architecture
aligns naturally with the flow of packets in high-throughput networking
environments \autocite{mueller-sigmod-2009}.

FPGA implementations of many core database operations have been developed.
Converting algorithms from CPU to FPGA is fairly straightforward, especially
with the help of HLS, but optimizing them is a focus of ongoing research
\autocite{fang-vldb-2020}. Converting simple operations like filter and
projection (removing some columns from a table before returning it) are largely
a solved problem \autocite{fang-vldb-2020}, but more complicated operations like
merge and sort have been implemented in many ways, with some showing significant
performance improvements over CPU versions
\autocite{leggett-trets-2025,moghaddamfar-damon-2021}.

Much of the recent research into using FPGAs for database acceleration focuses
on specialized Network Interface Cards (NICs) called SmartNICs. These contain a
small FPGA, which allows for some processing to be offloaded from the CPU at the
point of access to the network \autocite{strom,honeycomb}. However, the smaller
program space and reduced performance of these FPGAs limit how much work can be
moved onto them from other parts of the system. For instance, the
\citetitle{honeycomb} system proposed by \citeauthor{honeycomb} chooses to only
accelerate read operations, assuming a read-heavy workload \autocite{honeycomb}.
The structure of FPGAs incentivizes prioritizing common, simple operations
because of the resource multiplexing issues mentioned above
\autocite{honeycomb,moghaddamfar-damon-2021}.
